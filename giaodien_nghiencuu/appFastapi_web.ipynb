{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AT33yfAWU4w8"
      },
      "source": [
        "# **Clone and download models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTPcku76Axpu",
        "outputId": "9d6f1159-0de5-4938-eff7-05bb583cc168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "colabcode\n",
        "pyngrok\n",
        "fastapi\n",
        "python-multipart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzH1mTSvG0ay"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/A40405/STTR2022.git\n",
        "!git clone https://github.com/A40405/stablediffusion2022.git\n",
        "!git clone https://github.com/A40405/ngamcuukhoahoc.git\n",
        "!pip install -r requirements.txt\n",
        "!pip install -r STTR2022/requirements.txt\n",
        "!pip install -r stablediffusion2022/requirements.txt\n",
        "del _"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3oOUe_IlZVi",
        "outputId": "3df8a129-cf83-473c-9760-d1d28451076c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1oNt0YwJvyNQfrTSr2V3A5ee6AIKqvmLp\n",
            "From (redirected): https://drive.google.com/uc?id=1oNt0YwJvyNQfrTSr2V3A5ee6AIKqvmLp&confirm=t&uuid=4975f063-c551-40a6-a340-94c8a8d1fdcb\n",
            "To: /content/STTR2022/checkpoint_model/checkpoint0005.pth\n",
            "100%|██████████| 545M/545M [00:08<00:00, 66.7MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1pWOLw6ZiQJq0KkQyrZwNKeBVqEhWaamo\n",
            "From (redirected): https://drive.google.com/uc?id=1pWOLw6ZiQJq0KkQyrZwNKeBVqEhWaamo&confirm=t&uuid=5e5fbbd3-aa77-4d87-acab-ea4d580d1780\n",
            "To: /content/stablediffusion2022/checkpoints/768-v-noema.ckpt\n",
            "100%|██████████| 5.21G/5.21G [01:03<00:00, 82.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "%mkdir STTR2022/checkpoint_model -p\n",
        "%mkdir  stablediffusion2022/checkpoints -p\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "url = 'https://drive.google.com/uc?id=1oNt0YwJvyNQfrTSr2V3A5ee6AIKqvmLp'\n",
        "output = './STTR2022/checkpoint_model/checkpoint0005.pth'\n",
        "if not os.path.isfile(output):\n",
        "  gdown.download(url, output, quiet=False)\n",
        "\n",
        "# url = 'https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-nonema-pruned.ckpt'\n",
        "url = 'https://drive.google.com/uc?id=1pWOLw6ZiQJq0KkQyrZwNKeBVqEhWaamo'\n",
        "output = './stablediffusion2022/checkpoints/768-v-noema.ckpt'\n",
        "if not os.path.isfile(output):\n",
        "    gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e7KyfzPVDZz"
      },
      "source": [
        "# **Import package**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkBUHuxQ_GH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0dc332d-9fe4-498b-b8e0-9c79bf07aadd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
            "  _torch_pytree._register_pytree_node(\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "sys.path.append('/content/STTR2022')\n",
        "sys.path.append('/content/stablediffusion2022')\n",
        "sys.path.append('/content/nghiencuukhoahoc')\n",
        "import shutil\n",
        "import gc\n",
        "import os\n",
        "from PIL import Image\n",
        "from colabcode import ColabCode\n",
        "from typing import List\n",
        "from fastapi import FastAPI, File, Form, UploadFile, Request\n",
        "from fastapi.responses import HTMLResponse, FileResponse\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import argparse\n",
        "from STTR2022.run import get_args_parser, main as main1\n",
        "from stablediffusion2022.txt2img import main as main2, parse_args as parse_args2\n",
        "from stablediffusion2022.img2img import main as main3, parse_args as parse_args3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MR0vAOA5VN-t"
      },
      "source": [
        "# **App**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lsHVtlC_JD3j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21976e14-ddd8-41af-dc80-e3647ce36559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ],
      "source": [
        "ngrok.set_auth_token('2OGTbUuflDSL4YMX5ruu8tqA7FK_3eiMwLxKnM76H7RMt6dCG')\n",
        "app = FastAPI(title=\"FastAPI on Google Colab\", description=\"FastAPI and ColabCode\", version=\"1.0\")\n",
        "\n",
        "templates = Jinja2Templates(directory='./nghiencuukhoahoc/giaodien_nghiencuu/')\n",
        "\n",
        "\n",
        "@app.get('/')\n",
        "def index(request: Request):\n",
        "    return templates.TemplateResponse('index.html', {'request': request})\n",
        "@app.get('/style_images', response_class=HTMLResponse)\n",
        "def style_images_web(request: Request):\n",
        "    return templates.TemplateResponse('style_images.html', {'request': request})\n",
        "@app.get('/text_to_images', response_class=HTMLResponse)\n",
        "def text_to_images_web(request: Request):\n",
        "    return templates.TemplateResponse('text_to_images.html', {'request': request})\n",
        "@app.get('/image_to_image', response_class=HTMLResponse)\n",
        "def image_to_image_web(request: Request):\n",
        "    return templates.TemplateResponse('image_to_image.html', {'request': request})\n",
        "\n",
        "\n",
        "# app1\n",
        "@app.post('/style_images', response_class=HTMLResponse)\n",
        "async def upload_imgs_to_create_imgs(request: Request,\n",
        "                                     content_images: List[UploadFile] = File(..., description=\"Content image (JPG or PNG)\"),\n",
        "                                     style_images: List[UploadFile] = File(..., description=\"Style image (JPG or PNG)\")):\n",
        "    style_folder = './STTR2022/inputs/style'\n",
        "    if not os.path.exists(style_folder):\n",
        "        os.makedirs(style_folder)\n",
        "    else:\n",
        "        shutil.rmtree(style_folder)\n",
        "        os.makedirs(style_folder)\n",
        "\n",
        "    content_folder = './STTR2022/inputs/content'\n",
        "    if not os.path.exists(content_folder):\n",
        "        os.makedirs(content_folder)\n",
        "    else:\n",
        "        shutil.rmtree(content_folder)\n",
        "        os.makedirs(content_folder)\n",
        "\n",
        "    outputs_folder = './STTR2022/outputs'\n",
        "    if os.path.exists(outputs_folder) and os.listdir(outputs_folder):\n",
        "        shutil.rmtree(outputs_folder)\n",
        "\n",
        "    error_messages = []  # Danh sách thông báo lỗi\n",
        "\n",
        "    # Kiểm tra tệp Content image\n",
        "    for idx, content_image in enumerate(content_images):\n",
        "        if content_image.filename == '':\n",
        "            error_messages.append(f\"Content Image {idx+1} is empty.\")\n",
        "        else:\n",
        "            with open(os.path.join(content_folder, content_image.filename), 'wb') as f:\n",
        "                shutil.copyfileobj(content_image.file, f)\n",
        "\n",
        "    # Kiểm tra tệp Style image\n",
        "    for idx, style_image in enumerate(style_images):\n",
        "        if style_image.filename == '':\n",
        "            error_messages.append(f\"Style Image {idx+1} is empty.\")\n",
        "        else:\n",
        "            with open(os.path.join(style_folder, style_image.filename), 'wb') as f:\n",
        "                shutil.copyfileobj(style_image.file, f)\n",
        "\n",
        "    # Kiểm tra nếu có thông báo lỗi, trả về template với thông báo lỗi\n",
        "    if len(error_messages) > 0:\n",
        "        return templates.TemplateResponse('style_images.html', {'request': request, 'errors': error_messages})\n",
        "\n",
        "    # Xử lý tạo ảnh từ ảnh ở đây\n",
        "    parser = argparse.ArgumentParser('DETR outputs', parents=[get_args_parser()])\n",
        "    args = parser.parse_args([\n",
        "        \"--batch_size\", \"1\",\n",
        "        \"--style_loss_coef\", \"10\",\n",
        "        \"--fold_k\", \"5\",\n",
        "        \"--lr_backbone\", \"1e-5\",\n",
        "        \"--lr\", \"1e-5\",\n",
        "        \"--enc_layers\", \"6\",\n",
        "        \"--dec_layers\", \"6\",\n",
        "        \"--model_type\", \"nofold\",\n",
        "        \"--enorm\", \"--dnorm\", \"--tnorm\",\n",
        "        \"--cbackbone_layer\", \"2\", \"--sbackbone_layer\", \"4\",\n",
        "\n",
        "        \"--dataset_file\", \"demo\",\n",
        "        \"--resume\", \"./STTR2022/checkpoint_model/checkpoint0005.pth\",\n",
        "        \"--img_size\", \"512\",\n",
        "        \"--content_folder\", \"./STTR2022/inputs/content\",\n",
        "        \"--style_folder\", \"./STTR2022/inputs/style\",\n",
        "        \"--output_dir\", \"./STTR2022/outputs\",\n",
        "    ])\n",
        "\n",
        "    main1(args)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    success = True\n",
        "    return templates.TemplateResponse('style_images.html', {'request': request, 'success': success})\n",
        "\n",
        "\n",
        "# app2\n",
        "@app.post('/text_to_images', response_class=HTMLResponse)\n",
        "async def create_image_from_text(request: Request,\n",
        "                                 text: str = Form(default=None, description=\"Enter text in English\")):\n",
        "    if os.path.exists('stablediffusion2022/outputs'):\n",
        "        shutil.rmtree('stablediffusion2022/outputs')\n",
        "\n",
        "    if not text:\n",
        "        error_message = \"Empty text.\"\n",
        "        return templates.TemplateResponse('text_to_images.html', {'request': request, 'errors': error_message})\n",
        "    if not text.isascii():\n",
        "        error_message = \"Enter text in English.\"\n",
        "        return templates.TemplateResponse('text_to_images.html', {'request': request, 'errors': error_message})\n",
        "\n",
        "    # Xử lý tạo ảnh từ văn bản ở đây\n",
        "    parser = argparse.ArgumentParser(parents=[parse_args2()])\n",
        "    # text = \"photo of car brand mercedes maybach s650\"\n",
        "\n",
        "    opt = parser.parse_args([\n",
        "        \"--prompt\", text,\n",
        "        \"--outdir\", \"./stablediffusion2022/outputs/txt2img/768-v-noema\",\n",
        "        \"--ckpt\", \"./stablediffusion2022/checkpoints/768-v-noema.ckpt\",\n",
        "        \"--config\", \"./stablediffusion2022/configs/stable-diffusion/v2-inference-v.yaml\",\n",
        "        \"--n_samples\", \"1\",\n",
        "        \"--n_iter\", \"1\",\n",
        "        \"--H\", \"768\",\n",
        "        \"--W\", \"768\",\n",
        "        \"--device\", \"cuda\",\n",
        "    ])\n",
        "    main2(opt)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    success = True\n",
        "    return templates.TemplateResponse('text_to_images.html', {'request': request, 'success': success})\n",
        "\n",
        "\n",
        "# app3\n",
        "@app.post('/image_to_image', response_class=HTMLResponse)\n",
        "async def create_img_from_img_and_text(request: Request,\n",
        "                                       strength: float = Form(default=0.5, description=\"Strength value between 0 and 1\"),\n",
        "                                       text: str = Form(default=None, description=\"Entering text in English will have more accurate results\"),\n",
        "                                       images: List[UploadFile] = File(..., description=\"Sample images(JPG or PNG)\")):\n",
        "    sample_image_folder = './stablediffusion2022/inputs'\n",
        "    if not os.path.exists(sample_image_folder):\n",
        "        os.makedirs(sample_image_folder)\n",
        "    else:\n",
        "        shutil.rmtree(sample_image_folder)\n",
        "        os.makedirs(sample_image_folder)\n",
        "\n",
        "    if os.path.exists('stablediffusion2022/outputs'):\n",
        "        shutil.rmtree('stablediffusion2022/outputs')\n",
        "\n",
        "    if images[0].filename == '':\n",
        "        error_message = \"Empty image.\"\n",
        "        return templates.TemplateResponse('image_to_image.html', {'request': request, 'errors': error_message})\n",
        "    if not text:\n",
        "        error_message = \"Empty text.\"\n",
        "        return templates.TemplateResponse('image_to_image.html', {'request': request, 'errors': error_message})\n",
        "\n",
        "    img = Image.open(images[0].file)\n",
        "    img_size = img.size\n",
        "\n",
        "    if img_size[0] < 256 or img_size[1] < 256:\n",
        "        error_message = f\"input image must be larger than 256x256 but your input image size {img_size[0]}x{img_size[1]}\"\n",
        "        return templates.TemplateResponse('image_to_image.html', {'request': request, 'errors': error_message})\n",
        "\n",
        "    img.save(f\"{sample_image_folder}/{images[0].filename}\")\n",
        "\n",
        "    # Xử lý tạo ảnh từ ảnh ở đây\n",
        "    parser = argparse.ArgumentParser(parents=[parse_args3()])\n",
        "\n",
        "    input_file = os.path.join(sample_image_folder, os.listdir(sample_image_folder)[0])\n",
        "    opt = parser.parse_args([\n",
        "        \"--prompt\", text,\n",
        "        \"--init_img\", input_file,\n",
        "        \"--outdir\", \"./stablediffusion2022/outputs/img2img/768-v-noema/\",\n",
        "        \"--strength\", f\"{strength}\",\n",
        "        \"--n_samples\", '2',\n",
        "        \"--ckpt\", './stablediffusion2022/checkpoints/768-v-noema.ckpt',\n",
        "        \"--config\", \"./stablediffusion2022/configs/stable-diffusion/v2-inference-v.yaml\",\n",
        "        \"--device\", \"cuda\",\n",
        "    ])\n",
        "    main3(opt)\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    success = True\n",
        "    return templates.TemplateResponse('image_to_image.html', {'request': request, 'success': success})\n",
        "\n",
        "\n",
        "# zip1\n",
        "@app.get('/download_images1')\n",
        "def get_images_style():\n",
        "    directory = './STTR2022/outputs/test_outputs'\n",
        "    if not os.path.exists(directory):\n",
        "        return templates.TemplateResponse('style_images.html', {'errors': \"No output image yet\"})\n",
        "    zip_file = \"./STTR2022/outputs1.zip\"\n",
        "    if os.path.exists(zip_file):\n",
        "        os.remove(zip_file)\n",
        "\n",
        "    os.system(f'zip -r {zip_file} {directory}')\n",
        "    return FileResponse(zip_file, media_type='application/zip')\n",
        "\n",
        "\n",
        "# zip2\n",
        "@app.get('/download_images2')\n",
        "def get_images_txt2img():\n",
        "    directory = './stablediffusion2022/outputs/txt2img/768-v-noema/samples'\n",
        "    if not os.path.exists(directory):\n",
        "        return templates.TemplateResponse('text_to_images.html', {'errors': \"No output image yet\"})\n",
        "    zip_file = \"./stablediffusion2022/outputs2.zip\"\n",
        "    if os.path.exists(zip_file):\n",
        "        os.remove(zip_file)\n",
        "\n",
        "    os.system(f'zip -r {zip_file} {directory}')\n",
        "    return FileResponse(zip_file, media_type='application/zip')\n",
        "\n",
        "\n",
        "# zip3\n",
        "@app.get('/download_images3')\n",
        "def get_images_img2img():\n",
        "    directory = './stablediffusion2022/outputs/img2img/768-v-noema/samples'\n",
        "    if not os.path.exists(directory):\n",
        "        return templates.TemplateResponse('image_to_image.html', {'errors': \"No output image yet\"})\n",
        "    zip_file = './stablediffusion2022/outputs3.zip'\n",
        "    if os.path.exists(zip_file):\n",
        "        os.remove(zip_file)\n",
        "\n",
        "    os.system(f'zip -r {zip_file} {directory}')\n",
        "    return FileResponse(zip_file, media_type='application/zip')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWCvZF31etqv"
      },
      "source": [
        "# **main**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wkFN69dU0tw",
        "outputId": "c3e285e2-56f3-41ea-8de2-d04c01e9d083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [202]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:12000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://0298-34-82-206-198.ngrok-free.app\" -> \"http://localhost:12000\"\n",
            "INFO:     2405:4802:5e7b:9c80:6c15:32f:2da:7076:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2405:4802:5e7b:9c80:6c15:32f:2da:7076:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
            "INFO:     2405:4802:5e7b:9c80:6c15:32f:2da:7076:0 - \"GET /text_to_images HTTP/1.1\" 200 OK\n",
            "INFO:     2405:4802:5e7b:9c80:6c15:32f:2da:7076:0 - \"GET / HTTP/1.1\" 200 OK\n",
            "INFO:     2405:4802:5e7b:9c80:6c15:32f:2da:7076:0 - \"GET /text_to_images HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2024-02-14T08:58:49+0000 lvl=warn msg=\"Stopping forwarder\" name=http-12000-e5906183-3e8b-4291-9aeb-28457e373a9e acceptErr=\"failed to accept connection: Listener closed\"\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [202]\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    cc = ColabCode(port=12000, code=False)\n",
        "    cc.run_app(app=app)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VipzPjCe6j6"
      },
      "outputs": [],
      "source": [
        "!kill -9 -0"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "2e7KyfzPVDZz"
      ],
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}